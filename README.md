<div align="center">

<h3 align="center">Towards Accessible Document Layouts for Blind People</h3>
</div>

## Updates ğŸ”¥

We developed an interface to improve document accessibility for users with visual impairments. Our approach integrates a Document Layout Analysis (DLA) detection model with the ChatGPT API to generate a coherent reading order. The extracted metadata is then presented through tactile display interfaces for enhanced user interaction. ğŸš€!

- **08/10/2024**: ğŸ“„ Added dataset images.

<!-- ABOUT THE PROJECT -->
## About ğŸ“‹

This repository is part of our submission for the MDPI paper (currently under review) titled *"Designing a Tactile Document UI for 2D Refreshable Tactile Displays: Towards Accessible Document Layouts for Blind People"*

<p align="center">
  <img src="images/samples.gif" height="640"/>
</p>

## Dataset ğŸ“Š
| Split   | # images | # instance |
|---------|-------|----------|
| Train | x | x |
| Validation | x | x |
| Test | x | x |

### Installation ğŸ’»
```
tbd
pip install -r requirements.txt
```

## References ğŸ“
```
tbd
```

## Contact
Sara Zalabny: <Sara.Zalabny@neptunlab.org> 

Omar Moured: [https://www.linkedin.com/in/omar-moured/](https://www.linkedin.com/in/omar-moured/)
